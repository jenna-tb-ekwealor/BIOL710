---
title: "Multiple linear regression"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE,message=FALSE}
library(BIOL710)
library(learnr)
library(learnrhash)
library(tidyverse)
library(gradethis)
library(openintro)
library(infer)
tutorial_options(
  # use gradethis for checking
  exercise.checker = gradethis::grade_learnr
  )
knitr::opts_chunk$set(echo = FALSE)


```

## Getting Started

Many college courses conclude by giving students the opportunity to evaluate 
the course and the instructor anonymously. However, the use of these student 
evaluations as an indicator of course quality and teaching effectiveness is 
often criticized because these measures may reflect the influence of 
non-teaching related characteristics, such as the physical appearance of the 
instructor. The article titled, "Beauty in the classroom: instructors' 
pulchritude and putative pedagogical productivity" by Hamermesh and Parker 
found that instructors who are viewed to be better looking receive higher 
instructional ratings. 

Here, you will analyze the data from this study in order to learn what goes 
into a positive professor evaluation. The goal is to show you how to fit and evaluate the models that you will be using in your final project.

### Load packages

In this pre-lab, you will explore and visualize the data using the **tidyverse** suite of 
packages. The data can be found in the companion package for OpenIntro resources, **openintro**.

Let's load the packages.

```{r load-packages, exercise = T}
library(tidyverse)
library(openintro)
```

### The data

The data were gathered from end of semester student evaluations for a large 
sample of professors from the University of Texas at Austin. In addition, six 
students rated the professors' physical appearance. The result is a data frame 
where each row contains a different course and columns represent variables about 
the courses and professors. It's called `evals`.

```{r look, exercise = T}
glimpse(evals)
```

We have observations on 21 different variables, some categorical and some 
numerical. The meaning of each variable can be found by bringing up the help file:

```{r help-evals, exercise = T}
?evals
```

## Exploring the data

Make a plot of the distribution of `score`. 

```{r nvzlxsivbjxdhbqy, exercise = TRUE}
ggplot(___, aes(x = ___)) +  ___
```


```{r nvzlxsivbjxdhbqy-solution}
ggplot(evals, aes(x = score )) + geom_histogram()
```

```{r nvzlxsivbjxdhbqy-check}
# check code
gradethis::grade_code()
```

```{r isskew}
question("Is the distribution skewed?",
    answer("No, the distribution is symmetric."),
    answer("Yes, the distribution is skewed right."),
    answer("Yes, the distribution is skewed left.", correct = T),
    allow_retry = TRUE,
    random_answer_order = F
  )
```


Make a plot of the relationship between `score` and  beauty score `bty_avg` (we want to use beauty score to help us understand score) and describe this relationship. 

```{r wvmlhvlgkbnhonag, exercise = TRUE}
ggplot(___, aes(x = ___, y = ___))+___

```

```{r wvmlhvlgkbnhonag-solution}
ggplot(evals, aes(x = bty_avg, y = score))+geom_point()
```

```{r wvmlhvlgkbnhonag-check}
# check code
gradethis::grade_code()
```

Adapt your plot from above by using `col = gender` within `aes` to see how the relationship differs by gender of the faculty member. 

```{r wvmlhvlgkbnhonag2, exercise = TRUE}
ggplot(___, aes(x = ___, y = ___, col = gender))+___

```

```{r wvmlhvlgkbnhonag2-solution}
ggplot(evals, aes(x = bty_avg, y = score, col = gender))+geom_point()
```

```{r wvmlhvlgkbnhonag2-check}
# check code
gradethis::grade_code()
```


## Simple linear regression

```{r simpmod, exercise = T}
base_model <- lm(score ~ bty_avg, data = evals)
summary(base_model)
```

Using `geom_smooth` and choosing `method = "lm"` will add the simple linear regression line to the plot.

```{r plotsimp, exercise = T}
ggplot(evals, aes(x = bty_avg, y = score)) + geom_point() + geom_smooth(method = "lm", se = F)
```

```{r slopeint}
question("Interpret this slope in context.",
  answer("With a one unit increase in bty_avg comes a 0.067 unit increase in score."),
  answer("A one unit increase in bty_avg is associated with a 3,88 unit increase in score on average."),
  answer("A one unit increase in bty_avg is associated with a 0.067 unit increase in score on average.", correct = T),
  allow_retry = TRUE,
  random_answer_order = F
)
```

The last column `Pr(>|t|)` gives a p-value for the hypothesis test of statistical significance for each coefficient (in this case intercept and slope for `bty_avg`). In each case the null hypothesis is that the coefficient is equal to 0 and the alternative hypothesis is that the coefficient is not equal to zero. 

```{r intsig}
question("Is the intercept statistically significantly different from zero at the 0.01 signifcance level?",
  answer("Yes, 2e-16 < 0.1", correct = T),
  answer("Yes, 5.08e-05 < 0.1"),
    answer("No, 2e-16 < 0.1"),
  answer("No, 5.08e-05 < 0.1"),
  allow_retry = TRUE,
  random_answer_order = F
)
```

```{r slopesig}
question("Is the slope statistically significantly different from zero at the 0.01 signifcance level?",
  answer("Yes, 2e-16 < 0.1"),
  answer("Yes, 5.08e-05 < 0.1", correct = T),
    answer("No, 2e-16 < 0.1"),
  answer("No, 5.08e-05 < 0.1"),
  allow_retry = TRUE,
  random_answer_order = F
)
```


## Parallel Slopes

A parallel slope approach is denoted with a plus sign between two covariates.


```{r parallel, exercise = T}
parallel_slopes_model <- lm(score ~ bty_avg + gender, data = evals)
summary(parallel_slopes_model)
```

We can use `geom_abline` to specify the slope and intercept for each category so that we can draw two lines on the plot. When plotting two categories, #00BFC4 is the default color for the reference category and "#F8766D" is the default color for a second category, so we specify those to match the points. In your projects, you might want to do this more automatically. See [this reference](https://moderndive.github.io/moderndive/reference/geom_parallel_slopes.html) for guidance.

```{r plotparallel, exercise = T}
ggplot(evals, aes(bty_avg, score, col = gender)) + geom_point() + geom_abline(slope = 0.07416, intercept = 3.74734 + 0.17239, col = "#00BFC4") + geom_abline(slope = 0.07416, intercept = 3.74734 , col = "#F8766D")
```


```{r eqf}
question("Write the equation of the regression line for females.",
  answer("score = 3.75 + 0.07*bty_avg"),
  answer("score = 3.75 + 0.17 + 0.07*bty_avg"),
  answer("score_hat = 3.75 + 0.07*bty_avg", correct = T),
  answer("score_hat = 3.75 + 0.17 + 0.07*bty_avg"),
  allow_retry = TRUE,
  random_answer_order = F
)
```

```{r eqm}
question("Write the equation of the regression line for males.",
  answer("score = 3.75 + 0.07 * bty_avg"),
  answer("score = 3.75 + 0.17 + 0.07 * bty_avg"),
  answer("score_hat = 3.75 + 0.07 * bty_avg"),
  answer("score_hat = 3.75 + 0.17 + 0.07 * bty_avg", correct = T),
  allow_retry = TRUE,
  random_answer_order = F
)
```


## Interaction Model 

An interaction is denoted as a product (*) between two covariates. 

```{r interaction, exercise = T}
interaction_model <- lm(score ~ bty_avg * gender, data = evals)
summary(interaction_model)
```

Using `geom_smooth` and choosing `method = "lm"` will add the interaction linear regression line to the plot (ggplot knows to make a different line per gender because the points are colored by gender).

```{r plotinteration, exercise = T}
ggplot(evals, aes(x = bty_avg, y = score, col = gender)) + geom_point() + geom_smooth(method = "lm", se = F)
```

```{r eqf2}
question("Write the equation of the regression line for females.",
  answer("score_hat = 3.95 + 0.03 * bty_avg", correct = T),
  answer("score_hat = 3.95 + -0.18 + 0.03 * bty_avg"),
  answer("score_hat = 3.95 + -0.18 + (0.03 + 0.08) * bty_avg"),
  answer("score_hat = 3.95 + (0.03 + 0.08) * bty_avg"),
  allow_retry = TRUE,
  random_answer_order = F
)
```

```{r eqm2}
question("Write the equation of the regression line for males.",
  answer("score_hat = 3.95 + 0.03 * bty_avg"),
  answer("score_hat = 3.95 + -0.18 + 0.03 * bty_avg"),
  answer("score_hat = 3.95 + -0.18 + (0.03 + 0.08) * bty_avg", correct = T),
  answer("score_hat = 3.95 + (0.03 + 0.08) * bty_avg"),
  allow_retry = TRUE,
  random_answer_order = F
)
```


## Which is best?

One way to define "best" is to consider how much of the variability in the scores are explained by the model. Compare the multiple R-squared values for these three models. 

```{r rsq-setup}
base_model <- lm(score ~ bty_avg, data = evals)

parallel_slopes_model <- lm(score ~ bty_avg + gender, data = evals)

interaction_model <- lm(score ~ bty_avg * gender, data = evals)
```

```{r rsq, exercise = TRUE}
summary(base_model)
summary(parallel_slopes_model)
summary(interaction_model)
```


Note that as the models increase in complexity, the multiple R-squared value increases. This is always the case.Is that extra complexity worth it though? One way of telling is whether the extra terms (the extra intercept or extra slope term) are statistically significantly different than zero. If not, we cannot reject the null hypothesis that they are actually zero and that extra complexity may not be worth it.

## Checking conditions

Another way to decide which model is "best" is to determine which one meets the modeling assumptions best. Look at the different residual plots for the three models (`base_model`, `parallel_slopes_model` and `interaction_model`) and compare.

```{r checkcond-setup}
base_model <- lm(score ~ bty_avg, data = evals)

parallel_slopes_model <- lm(score ~ bty_avg + gender, data = evals)

interaction_model <- lm(score ~ bty_avg * gender, data = evals)
```

```{r checkcond, exercise = TRUE}

ggplot(data = ___, aes(x = .resid)) +
  geom_histogram() +
  xlab("Residuals")

ggplot(data = ___, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  xlab("Fitted values") +
  ylab("Residuals")
```


## Submit checkpoint

```{r context="server"}
learnrhash::encoder_logic(strip_output = T)
```

```{r encode, echo=FALSE}
learnrhash::encoder_ui(
  ui_before = div(strong("Submit your hash in the form below."), br(), br()),
  ui_after  = learnrhash::iframe_ui(
    src = "https://docs.google.com/forms/d/e/1FAIpQLSf0FKvlOHfchtSxwIpD9Jo65sDlTjeokodsO1vP64rLcVYZ2A/viewform?usp=header",
    width="900px", height= "1000px"
  )
)
```


* * *

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a> then was adapted and learnr-ified by Sara Stoudt, and further adapted and biologified by Jenna Ekwealor.
